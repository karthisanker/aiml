{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification on Restaurant Reviews using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Dropout,LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Restaurant_Reviews.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: Liked, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Liked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords     #stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = list(set(stopwords.words('english')))\n",
    "if 'not' in stop_word:\n",
    "    stop_word.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(X):\n",
    "    preprocessed_reviews = []\n",
    "    # tqdm is for printing the status bar\n",
    "    for txt in X:\n",
    "        \n",
    "        txt = re.sub(r'<.*?>','',txt)    #remove tags\n",
    "        #txt = text_preprocess(txt)\n",
    "        #txt = re.sub(\"\\S*\\d\\S*\", \"\", txt)\n",
    "        txt = re.sub('[^A-Za-z]+', ' ', txt)  #remove everything except A-Z and a-z\n",
    "        txt = re.sub(r'\\s+',' ',txt)        # convert more than one space's into one\n",
    "       \n",
    "        txt = ' '.join(e.lower() for e in txt.split() if e.lower() not in stop_word)\n",
    "        \n",
    "        preprocessed_reviews.append(txt)\n",
    "    return np.array(preprocessed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=clean(df.Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews\n",
    "y = df.Liked.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([500, 500])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=.20,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert texts into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words=1600  \n",
    "\n",
    "tokenize = Tokenizer(total_words)   #tokenize our input data\n",
    "tokenize.fit_on_texts(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found total 1645 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenize.word_index\n",
    "print('Found total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = tokenize.texts_to_sequences(x_train)\n",
    "#X_cv_new = tokenize.texts_to_sequences(X_cv)\n",
    "X_test_new = tokenize.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 8, 637, 372]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inv_index = {v: k for k, v in tokenize.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 15\n",
    "X_train = sequence.pad_sequences(X_train_new, maxlen=max_words,padding='post',truncating='post')\n",
    "X_test = sequence.pad_sequences(X_test_new, maxlen=max_words,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 15, 32)            51200     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 15, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 15, 64)            24832     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 216,449\n",
      "Trainable params: 216,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(total_words, embed_vector_length, input_length=max_words))\n",
    "\n",
    "#model.add(LSTM(64))\n",
    "model.add(LSTM(32,dropout=.2,return_sequences=True))\n",
    "\n",
    "model.add(LSTM(64,dropout=.2,return_sequences=True))\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(.001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'saved_model/model.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,mode='max', monitor='val_acc', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6938 - acc: 0.4800 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 1s 664us/sample - loss: 0.6933 - acc: 0.5038 - val_loss: 0.6927 - val_acc: 0.5100\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 1s 673us/sample - loss: 0.6909 - acc: 0.5312 - val_loss: 0.6859 - val_acc: 0.5150\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 1s 689us/sample - loss: 0.5823 - acc: 0.7462 - val_loss: 0.6735 - val_acc: 0.7650\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.2678 - acc: 0.9087 - val_loss: 0.5139 - val_acc: 0.8050\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 1s 648us/sample - loss: 0.1656 - acc: 0.9463 - val_loss: 0.7201 - val_acc: 0.8000\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 1s 652us/sample - loss: 0.1196 - acc: 0.9600 - val_loss: 0.6570 - val_acc: 0.7900\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 1s 661us/sample - loss: 0.0688 - acc: 0.9775 - val_loss: 0.9108 - val_acc: 0.7650\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 1s 689us/sample - loss: 0.0628 - acc: 0.9775 - val_loss: 0.9368 - val_acc: 0.7750\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 1s 638us/sample - loss: 0.0477 - acc: 0.9825 - val_loss: 0.8604 - val_acc: 0.7600\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.0295 - acc: 0.9887 - val_loss: 1.1456 - val_acc: 0.7600\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 1s 648us/sample - loss: 0.0295 - acc: 0.9912 - val_loss: 1.2241 - val_acc: 0.7700\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 1s 634us/sample - loss: 0.0354 - acc: 0.9862 - val_loss: 1.1285 - val_acc: 0.7600\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 1s 648us/sample - loss: 0.0294 - acc: 0.9912 - val_loss: 1.0303 - val_acc: 0.7550\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.0149 - acc: 0.9937 - val_loss: 1.2600 - val_acc: 0.7700\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 1s 649us/sample - loss: 0.0328 - acc: 0.9900 - val_loss: 1.3635 - val_acc: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 1s 654us/sample - loss: 0.0194 - acc: 0.9925 - val_loss: 1.1724 - val_acc: 0.7450\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 1s 654us/sample - loss: 0.0241 - acc: 0.9900 - val_loss: 1.1176 - val_acc: 0.7350\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 1s 691us/sample - loss: 0.0214 - acc: 0.9925 - val_loss: 1.3151 - val_acc: 0.7400\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 1s 667us/sample - loss: 0.0173 - acc: 0.9937 - val_loss: 1.2643 - val_acc: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec1648b910>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,batch_size=64, epochs=20,validation_data=(X_test,y_test),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 200us/sample - loss: 1.2730 - acc: 0.7700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2730195140838623, 0.77]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('restaurant_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('saved_model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.5325 - acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5324648571014404, 0.8]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 'food was so amazing'  #+ve review\n",
    "test2 = \"I visited this outlet during Navratra. One of my friends recommended me to try their Navratra \\\n",
    "         special Mitthi lassi and Paneer roll. It's was so good to satisfy you in your fasts.\\\n",
    "         The outlet is quite spacious with a very nice ambience. You can also try many items from a long \\\n",
    "        list in the menu.\"\n",
    "\n",
    "\n",
    "\n",
    "test_samples = [test1,test2]\n",
    "\n",
    "review = clean(test_samples)\n",
    "test_token = tokenize.texts_to_sequences(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_pad = sequence.pad_sequences(test_token,maxlen=max_words,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_samples_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_classes(test_samples_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
